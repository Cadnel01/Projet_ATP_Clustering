---
documentclass: "compterendu"
lang: true
babel-lang: "french"
geometry:
  - left=1.5cm
  - right=1.5cm
  - top=1.5cm
  - bottom=2cm
title: "Clustering sur les joueurs ATP de l'année 2012."
author: 
  - EHRE
  - ABBASSI
  - BOUR
  - SANTOU
  - GNANASEELAN-BENEDICT
  - HOUNKPATIN
email:
  - Alicia
  - Mehdi
  - Léon
  - Emmanuel
  - Jathurshan
  - Cadnel
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: "Réalisation d'un clustering sur les joueurs ATP de l'année 2012."
anac: "2020-2021"
diplome: "Master 2 - Statistiques pour l'Evaluation et la Prévision"
module: "SEP0922"
enseig: "Philippe Regnault"
evaluation: "Clustering"
output: 
  bookdown::pdf_book:
    template: template.tex
    fig_caption: yes
    keep_tex: yes
    toc: yes
bibliography: biblio_cr-urca.bib
biblio-style: plain
link-citations: yes
---

```{r, include = FALSE}

library(tidyverse)
library(factoextra)
library(FactoMineR)
library(NbClust)
library(dendextend)
library(fpc)
library(devtools)
library(kableExtra)
#install_github("larmarange/JLutils")

```

```{r, include = FALSE}

#Ce bloc configure quelques options d'affichage pour les blocs R
library('knitr')
opts_chunk$set(comment = '', echo = FALSE,  tidy = TRUE, 
               fig.pos = 'ht!', fig.align='center', fig.width= 4.5, fig.height = 3.2)

```

```{r, include = FALSE}

players <- read_csv("tennis_atp/atp_players.csv", col_names = FALSE)
names(players) <- c("id", "firstname", "lastname", "hand", "birthday", "nat")

df <- read_csv("tennis_atp/atp_matches_2012.csv")

```

```{r, include = FALSE}

# Créer un tableau agrégé des gagnants
df_winner <- df  %>%
  group_by(winner_name) %>%
  summarise(w_ace = mean(w_ace, na.rm = TRUE),
            w_ht = winner_ht,
            w_age= round(winner_age),
            w_stIn = mean(w_1stIn, na.rm = TRUE),
            w_stWon = mean(w_1stWon, na.rm = TRUE),
            w_svpt = mean(w_svpt, na.rm = TRUE),
            w_svgms = mean(w_SvGms, na.rm = TRUE),
            w_bpSaved = mean(w_bpSaved, na.rm = TRUE),
            w_bpFaced = mean(w_bpFaced, na.rm = TRUE),
            w_min = mean(minutes, na.rm = TRUE))
df_winner <- distinct(df_winner,.keep_all = TRUE)

# Créer un tableau agrégé des perdants
df_loser <- df  %>%
  group_by(loser_name) %>%
  summarise(l_ace = mean(l_ace, na.rm = TRUE),
            l_ht = loser_ht, 
            l_age= round(loser_age),
            l_stIn = mean(l_1stIn, na.rm = TRUE),
            l_stWon = mean(l_1stWon, na.rm = TRUE),
            l_svpt = mean(l_svpt, na.rm = TRUE),
            l_svgms = mean(l_SvGms, na.rm = TRUE),
            l_bpSaved = mean(l_bpSaved, na.rm = TRUE),
            l_bpFaced = mean(l_bpFaced, na.rm = TRUE),
            l_min = mean(minutes, na.rm = TRUE))
df_loser <- distinct(df_loser,.keep_all = TRUE)


# Donner le même nom du variable au "winner_name" et "loser_name"  
df_loser <- rename(df_loser, player = loser_name )
df_winner <- rename(df_winner, player = winner_name)

# Jointure des tables
df_player <- full_join(df_winner, df_loser, by = "player")

# Combinaison des variables
df_player <- mutate(df_player, ace = w_ace + l_ace,
                    height = case_when(w_ht == l_ht ~ w_ht, w_ht != l_ht ~ l_ht),
                    age = round(max(w_age,l_age)),
                    stin = w_stIn  + l_stIn,
                    stWon = w_stWon + l_stWon,
                    svpt = w_svpt +l_svpt,
                    svgms = w_svgms + l_svgms,
                    bpSaved = w_bpSaved + l_bpSaved,
                    bpFaced = w_bpFaced + l_bpFaced,
                    min = l_min + w_min) %>%
  select(ace, height, age, stin, stWon, svpt, svgms, bpSaved, bpFaced, min)

# Supprimer les valeurs manquantes
df_player <- distinct(df_player,.keep_all = TRUE)
df_player %>%
  select(ace, height, stin, stWon, svgms, bpSaved, bpFaced, min) %>%
  drop_na() -> df_clean
df_clean <- as.data.frame(df_clean)
rownames(df_clean) <- df_clean[,1]
df_clean <- df_clean[,-1]

```


# Contextualisation

  Au tennis, il existe différents styles de jeu : les défenseurs-contreurs, les attaquants de fond de court, les attaquants de type service-volée et les joueurs complets. Il ne faut pas oublier que chaque joueur est différent pour un même style de jeu. En effet, la tactique pourra être différente en fonction de l'adversaire et en fonction de l'état physique et psychologique du joueur.

Notre objectif est de déterminer différents profils de joueurs selon leur type de jeu, en se basant sur l'année 2012 des résultats des matchs ATP.


## Choix des variables

  Nos bases de données correspondent aux résultats des matchs de tennis des circuits professionnels ATP, téléchargeables depuis les dépôts GitHub de Jeff Sackmann. L’objectif est de rendre compte du plus large aspect possible en terme de jeu pratiqué. Au total, ce sont 8 variables explicatives numériques qui ont été sélectionnées :

* minutes : La durée du match
* l/w_ace : Nombre des services gagnants par match (par match)
* l/w_df : Nombre de doubles-fautes commises par le joueur (par match)
* l/w_svpt : Nombre de fois où le joueur a servi (par match)
* l/w_1stIn : Nombre de premiers services réussis (par match)
* l/w_2ndWon : Nombre de points gagnés après le deuxième service (par match)
* l/w_SvGms : Nombre de jeux de service gagnés (par match)
* l/w_bpSaved : Nombre de balles de break sauvées (par match)
* l/w_bpFaced : Nombre de balles de break subies (par match)
* loser/winner_ht : La taille du joueur

# Clustering

  Nous souhaitons faire un clustering pour séparer les joueurs ATP sur la saison 2012 en différents groupes de joueurs, caractérisés principalement par leur style de jeu.

## Choix du partitionnement

  Pour réaliser ce clustering, nous avons comparé les résultats des méthodes Kmeans et de classification ascendante hiérarchique (CAH). Dans un premier temps, il faut trouver le nombre optimal de clusters. Pour la méthode des kmeans, nous avons utilisé la fonction nbclust du package NbClust, nous donnant le nombre optimal de clusters, avec comme distance choisie la distance euclidienne.

```{r, include = FALSE,echo= FALSE}

set.seed(123)
df_kmeans <- as.data.frame(scale(df_clean, center=T, scale=T))
nb <- NbClust(df_kmeans, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans")
a<-invisible(fviz_nbclust(nb,print.summary = T))
```

```{r}
plot(a)
```

L'ensemble des critères de recherche du nombre optimal de clusters pour la CAH propose un nombre optimal de clusters de 3. Cependant, pour être sûr de trouver le meilleur partitionnement, nous allons comparer la CAH à 3 clusters avec la CAH à 4 clusters.


```{r tab1, echo = FALSE, eval = TRUE}

`Méthode`= c("ward.D","single","complete","average","mcquitty","median","centroid","ward.D2")
`Nombre de clusters`=  c("3","3","3","3","3","3","3","3")
tab <- cbind(`Méthode`,`Nombre de clusters`)
kable(tab, caption="(ref:tab1)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab1) Nombre de clusters optimal pour la méthode de CAH selon les critères.

### Comparaison des coefficients de silhouette

  Dans un premier temps, nous allons comparer les coefficients de silhouette des différents partitionnements.

```{r, echo = FALSE, eval = TRUE}

set.seed(123)
km <- kmeans(df_kmeans, 4)
df_clean$classe_km <- km$cluster
# Coefficients de silhouette
#si <- cluster::silhouette(km$cluster,dist(df_kmeans,"euclidean"))
#plot(si)
#factoextra::fviz_silhouette(si) + ggplot2::ylim(-1,1) 
#trouver comment prendre que le graph et pas les affichages console

```


```{r tab2, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Nombre d'individus`=  c("24","14","47","102")
`Coefficients de silhouette moyens`=  c("0,29","0,18","0,28","0,18")
tab <- cbind(`Cluster`,`Nombre d'individus`,`Coefficients de silhouette moyens`)
kable(tab, caption="(ref:tab4)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab2) Coefficients de silhouette moyens avec la méthode des Kmeans à 4 clusters.


```{r, echo = FALSE, eval = TRUE, message = FALSE}

df_CAH <- as.data.frame(scale(df_clean, center=T, scale=T))
D_cah <- dist(df_CAH,"euclidean")
CAH <- hclust(D_cah, method = "ward.D2")

# Comparaison 3 - 4 clusters avec CAH
clu_3 <- cutree(CAH,3)
clu_4 <- cutree(CAH,4)
si_cah_3 <- cluster::silhouette(clu_3, D_cah)
si_cah_4 <- cluster::silhouette(clu_4, D_cah)
df_CAH$classe <- clu_4
df_clean$classe_hc <- df_CAH$classe
plot(si_cah_3)
plot(si_cah_4)
# s3 <- factoextra::fviz_silhouette(si_cah_3) + ggplot2::ylim(-1,1)
# s4 <- factoextra::fviz_silhouette(si_cah_4) + ggplot2::ylim(-1,1)
# gridExtra::grid.arrange(s3,s4, ncol = 2, nrow = 1)
# trouver comment prendre que le graph et pas les affichages console


```

```{r tab3, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3")
`Nombre d'individus`=  c("24","14","149")
`Coefficients de silhouette moyens`=  c("0,49","0,31","0,44")
tab <- cbind(`Cluster`,`Nombre d'individus`,`Coefficients de silhouette moyens`)
kable(tab, caption="(ref:tab3)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab3) Coefficients de silhouette moyens avec la méthode CAH à 3 clusters.


```{r tab4, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Nombre d'individus`=  c("24","14","47","102")
`Coefficients de silhouette moyens`=  c("0,46","0,28","0,29","0,38")
tab <- cbind(`Cluster`,`Nombre d'individus`,`Coefficients de silhouette moyens`)
kable(tab, caption="(ref:tab4)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab4) Coefficients de silhouette moyens avec la méthode CAH à 4 clusters.

Les coefficients de silhouette sont meilleurs avec la méthode de la CAH plutôt qu'avec les Kmeans. De plus, à l'aide de la fonction cluster_similarity du package clusteval, les indices de Jaccard (égal à 1 ici) et de Rand (1 également) nous montrent qu'un kmeans à 4 clusters nous donne la même partition qu'une CAH à 4 clusters. Le choix se fait donc entre une CAH à 3 ou 4 clusters. Pour faire ce choix, il faut comparer les inerties des classifications. 

### Comparaison des inerties

Pour avoir un bon partitionnement, il nous faut minimiser son inertie intraclasse et maximiser son inertie interclassse. C'est pourquoi nous comparons maintenant les inerties intra et interclasse des partitionnement par CAH à 3 clusters et par CAH à 4 clusters.

```{r, include = FALSE}

#Les fonctions d'inertie

inertie_cor<-function(df,p=NULL){
  if (is.null(p)){ p <- rep(1,nrow(df))}
  g <- ( p %*% as.matrix(df) ) / sum(p)
  iner <- 0
  for (i in seq(nrow(df))){ iner <- iner + sum((df[i,] - g)^2) * p[i]   }
  return(iner)
}

inertie_inter_cor<-function(df,lab){
  M<-matrix(rep(0,ncol(df)*length(unique(lab))),ncol = ncol(df))
  for (k in unique(lab)){
    M[k,]<-unname(colMeans(df[which(lab==k),]))
  }
  return(inertie_cor(data.frame(M),unname(table(lab))))
}

inertie_intra_cor <- function(df,lab){
  res <- rep(0,length(unique(lab)))
  for (i in unique(lab)) {
    res[i] <- inertie_cor(df[which(lab==i),])
  }
  return(sum(res))
}

```


```{r tab5, echo = FALSE, eval = TRUE}

`CAH`= c("Intertie interclasse","Intertie interclasse")
`3 clusters`=  c("976,72","900,72")
`4 clusters`=  c("704,78","1172,67")
tab <- cbind(`CAH`,`3 clusters`,`4 clusters`)
kable(tab, caption="(ref:tab5)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab5) Inertie intra et interclasse par la méthode de CAH à 3 et 4 clusters.

La CAH à 4 clusters minimise le mieux l'inertie intraclasse et maximise le mieux l'inertie interclasse, en comparaison avec la CAH à 3 clusters, et ce phénomène a été vérifié en comparant avec les résultats des Kmeans. Ainsi, la méthode sélectionnée est la méthode des CAH à l'aide du critère de ward avec 4 clusters. 

(ref:clust) Clustering par la méthode de CAH avec la distance euclidienne et le critère de ward.

```{r clust, fig.cap="(ref:clust)", echo = FALSE, eval = TRUE}

factoextra::fviz_cluster(list(data=df_CAH, cluster=clu_4),geom="point", data = df_CAH, main='')

```

## Les clusters - Interprétation

  Nous allons maintenant étudier nos 4 clusters obtenus à l'aide de la méthode de CAH, afin de mieux comprendre comment ils se distinguent les uns des autres, et déterminer le q style de jeu pratiquer par chacun d’entre eux. Il serait intéressant de voir si jamais certains groupes sont « complémentaires » avec d’autres (au niveau des valeurs prises par les indicateurs statistiques), ainsi que d’observer la répartition des plus grands joueurs de tennis parmi ces groupes.


  Le premier cluster se démarque des autres sur plusieurs points. Tout d'abord, le groupe se caractérise par 3/4 des joueurs avec une taille en dessous de la moyenne (1m85) et un nombre d'aces réalisés inférieur à la moyenne pour plus des 3/4 des joueurs (Annexe 1). De plus, les 24 joueurs de ce premier cluster réalisent moins de services que les autres clusters, mais ont un pourcentage de services réussis du premier coup équivalent à celui des autres clusters (environ 60%). Cependant, leur performance au niveau des points marqués lors du premier échange est beaucoup plus faible que pour les autres clusters (Annexe 2). De même, ils ont un plus faible taux de break points sauvés et rencontrés que pour les autres clusters. En effet, ils ne sauvent en moyenne que 51% des break points rencontrés tandis que la moyenne est au minimum de 60% dans les autres clusters (Annexe 3). Enfin, ce cluster est composé de joueurs jouant des matchs beaucoup plus courts en moyenne que pour les joueurs des autres clusters (Annexe 4). Cela pourrait s'expliquer par le fait de ne pas jouer de Grand Chelems. 

Au final, ce groupe serait composé des joueurs plutôt de petite taille par rapport aux autres, n'ayant pas un service ou une attaque performants. De plus, ils joueraient des matchs plus courts en moyenne, ce qui pourrait provenir du fait qu'ils ne jouent pas ou peu de Grands Chelems. Tout ceci pourrait avoir un lien avec le fait que ce cluster est caractérisé par des joueurs plutôt jeunes. En effet, 50% des joueurs ont moins de 26 ans et 75% moins de 28 ans, alors que l'age moyen de l'ensemble des joueurs ATP de 2012 est de 27 ans. Les joueurs de ce cluster sont donc en général plus jeunes que la moyenne et auraient donc moins d'expérience.




  Le deuxième cluster est composé de 14 joueurs. La taille des joueurs de ce cluster varie entre 1m73 et 1m90, avec une moyenne de 1m84. Ces joueurs sont relativement grands par rapport aux groupes 1 et 4 (Annexe 1).
De plus, les joueurs réussissent en moyenne 61% de leurs premiers services, ce qui est équivalent aux autres clusters. Cependant, ce groupe se positionne à la tête des clusters en terme de gain de points remportés après le premier échange. Les joueurs de ce cluster s'illustrent donc avec une moyenne d'environ 85 points par match, ce qui est clairement supérieur aux moyennes des autres clusters. De même, ils réalisent 11% d'aces parmi leurs services réussis, ce qui est le deuxième meilleur taux parmis nos clusters. Enfin, dans la catégorie des points de break sauvés, ce cluster fait encore la différence avec 63% de breaks sauvés en moyenne par match, ce qui est supérieur aux moyennes des autres clusters.

En définitive,  les joueurs de ce cluster ont une taille autour de la moyenne général et ont l'avantage au niveau des points de break sauvés. De plus, ils ont la capacité de gagner rapidement des points dès le premier échange, ce qui justifie leur reussite. Ils réalisent donc d'énormes performances au niveau du nombre de points gagnés dès le premier échange. On a donc des joueurs qui sont très bons en service et dominateurs dans l'échange. 

### Cluster 3

```{r}
df_clean %>% 
  ggplot()+geom_boxplot(mapping = aes(x = as.character(classe_hc), y = height,
                                      fill = as.character(classe_hc) ))+  xlab("Classeur")+labs(fill="Classeur")
#Statistiques de la variable « height » (moyenne, min, max)
#summary(Base3$height)
```
Les joueurs dans ce classeur 3 ont des très grandes tailles qui dépassent 1m92 par rapport aux joueurs des autres classeurs qui ont une taille moyenne qui ne dépasse pas 1m85

```{r}
df_clean %>% 
  ggplot()+geom_boxplot(mapping = aes(x = as.character(df_clean$classe_hc), y = bpFaced,
                                      fill = as.character(df_clean$classe_hc) ))+
    xlab("Classeur")+labs(fill="Classeur")
```
Les joueurs dans ce classeur 3 ont tendances à jouer des bons services. Le nombre moyen des services gagnants par match pour les joueurs de ce classeur est élevé par rapport aux autres  (18 services gagnants par match pour ce classeur tandis que cette moyenne ne dépasse pas 13 services chez les autres)
Le Nombre de service réussis du premier coup est  au-dessus de la moyenne et prend la deuxième place parmi les classeurs
```{r}
df_clean %>% 
  ggplot()+geom_boxplot(mapping = aes(x = as.character(df_clean$classe_hc), y = stWon,
                                      fill = as.character(df_clean$classe_hc) ))+
  xlab("Classeur")+labs(fill="Classeur")


```
Le Nombre de fois où le joueur a gagné le premier point dès le premier service est au-dessus de la moyenne (73 par match) 

Les joueurs de ce classeur ont une grande taille, ce qui leurs donnent un grand avantage dans leurs services.

### Cluster 4

```{r, include = FALSE}
df_clean %>% filter(classe_hc == 4) -> Base4
Base4 <- Base4[,-c(9,10)]
```

Le quatrième cluster contient `r round(nrow(Base4)/nrow(df_clean)*100,2)`% observations. Les joueurs les plus connus dans ce cluster sont notamment Rafael Nadal et Stanislas Wawrinka. Les joueurs qui composent ce groupe, ont une moyenne d'âge de 27 ans. Pour la plupart, ce sont des joueurs expérimentés du circuit ATP. Les joueurs font en moyenne `r round(mean(Base4$height),2)` cm. Les joueurs de ce groupe sont donc généralement plus petit de taille que les joueurs des autres clusters.

De plus, tous les joueurs de ce groupe sont généralement bons au service. En effet, ils présentent un taiux de réussite de  plus de 61% de leurs premiers services, c'est le meilleur taux de nos clusters (Annexe 3). Par ailleurs, ces joueurs sont aussi très forts sur les balles de break, car lorsqu'ils sont dans une telle situation, ils arrivent à la sauver 60% du temps. Le graphique (Annexe 5) permet de montrer la corrélation entre le nombre de breaks auquel les joueurs font face et le nombre de breaks qu'ils ont sauvés; on aperçoit ainsi clairement que lorsqu'ils subissent des balles de break, il est plus probable que ces derniers arrivent à les sauver. Enfin, ce groupe joue en moyenne 3h41, étant donné que certains de ces joueurs participent aux Grands Chelems, qui se jouent en 3 sets gagnants et non 2. Cela explique en partie qu'ils jouent plus que la moyenne. Parmi ces joueurs, on peut noter la présence de grands noms du ténnis mondial tels que Rafael Nadal, Gaël Monfils, Lleyton Hewitt ou encore Stan Wawrinka. 
La présence de Jan Hernych et Denis Gremelmayr suscite toutefois quelques questions. En effet, ces 2 joueurs ne correspondent pas aux critères cités plus haut (Annexe 6). Ils doivent probablement jouer avec un style de jeu légèrement différent, ce que nous verrons en annexes.

# Conclusion

A FAIRE 

# (APPENDIX) Annexes {-}

## Annexe 1 : Comparaison du taux d'aces réalisés et de la taille des joueurs dans les différents clusters.


(ref:ace) Répartition du nombre de aces et de la taille des joueurs au sein des clusters

```{r ace, fig.cap="(ref:ace)", echo = FALSE, eval = TRUE}

df_clean %>% 
  ggplot() + 
  geom_boxplot(mapping = aes(x = as.character(classe_hc), y = ace, fill = as.character(classe_hc) )) +
  labs(fill = 'Clusters', y = 'Nombre moyen de aces', x = '') -> g_age

df_clean %>% 
  ggplot() + 
  geom_boxplot(mapping = aes(x = as.character(classe_hc), y = height, fill = as.character(classe_hc) )) +
  labs(fill = 'Clusters', y = 'Taille (en cm)', x = '') -> g_height

gridExtra::grid.arrange(g_age, g_height, ncol = 2, nrow = 1)

```

Le taux d'aces par clusters semble très différent. En effet, les joueurs du cluster 1 ont un taux d'aces plus faible que la moyenne (score de 11) pour la quasi-totalité des joueurs. Les joueurs du cluster 4 sont quand à eux 75% à avoir un taux plus faible que la moyenne. Concernant le cluster 2, les résultats s'améliorent avec plus de 25% des joueurs ayant un taux d'aces au dessus de la moyenne. Enfin le cluster 3 se démarque par la quasi-totalité de ses joueurs ayant un taux d'aces au dessus de la moyenne. En prenant le pourcentage d'aces par rapport au nombre de services réussis, ce phénomène se confirme. En effet, le cluster 3 se démarque avec en moyenne 18% d'aces parmi leurs services réussis. Les clusters 1, 4 et 2 se retrouvent avec respectivement 8,8% , 9% et presque 11%. On retrouve bien les clusters 1 et 4 avec le moins d'aces réalisés et le cluster 2 avec des meilleurs performances, mais encore loin de celles du cluster 3.


```{r tab6, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Pourcentage moyen de ace`=  c("8,76","10,84","18,55","9,07")
tab <- cbind(`Cluster`,`Pourcentage moyen de ace`)
kable(tab, caption="(ref:tab6)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab6) Pourcentage moyen d'aces par clusters.

Il y a un phénomène similaire concernant la taille des joueurs au sein des clusters. En effet, le cluster 1 et 4 ayant les moins bons taux d'aces ont également les joueurs les plus petits : 75% de leurs joueurs sont plus petits que la moyenne des joueurs ATP de 2012, qui est de 1m85. Les joueurs du cluster 2 ont une taille plutôt bien répartie autour de la moyenne. Enfin, le cluster 3 se démarque par des joueurs de grande taille, la quasi-totalité des joueurs ont une taille supérieur à la moyenne de 1m85.

On remarque donc une forte corrélation entre le fait d'être de grande taille et d'avoir une meilleure performance dans la réalisation d'aces.

## Annexe 2 : Rapport brek points sauvés/rencontrés pour chaque cluster

```{r tab7, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Pourcentage moyen de points de break sauvés`=  c("51,15","63,54","63,01","59,69")
tab <- cbind(`Cluster`,`Pourcentage moyen de points de break sauvés`)
kable(tab, caption="(ref:tab7)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab7) Pourcentage moyen de points de break sauvés par clusters.

Lorsque l'on regarde le pourcentage moyen de break points sauvés, on remarque que les joueurs du cluster 1 ne sauvent que 51% des breaks, tandis que pour les autres clusters, ce pourcentage est au minimum de 60%. En particulier, les les joueurs des clusters 2 et 3 ont des pourcentages de réussite d'environ 63%.

## Annexe 3 : Comparaison des services réussis pour chaque cluster

(ref:stin) Répartition du nombre moyen de services réussis au sein des clusters

```{r stin, fig.cap="(ref:stin)", echo = FALSE, eval = TRUE}

df_clean %>% 
  ggplot() + 
  geom_boxplot(mapping = aes(x = as.character(classe_hc), y = stin, fill = as.character(classe_hc) )) +
  labs(y = 'Nombre moyen de services réussis', x = '',fill ='Clusters')

```

Les taux de premiers services réussis semblent hétérogènes selon les clusters. En effet, les joueurs du cluster 2 semblent se détacher avec de meilleures performances. A l'opposé, les joueurs du cluster 1 semblent avoir plus de difficultés à réussir leur service du premier coup. Cependant, lorsque l'on regarde le taux de services réussis en fonction du nombre de services faits, on observe que dans tous les clusters, le pourcentage moyen de premiers services réussis est d'environ 60%. Le taux de premiers services réussis n'est donc pas un critère déterminant pour différencier les différents clusters.


```{r tab8, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Pourcentage de services réussis du premier coup`=  c("59,43","60,93","61,34","60,89")
tab <- cbind(`Cluster`,`Pourcentage de services réussis du premier coup`)
kable(tab, caption="(ref:tab8)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab8) Pourcentage de premiers services réussis par clusters.


## Annexe 4 : Comparaison de la durée moyenne des matchs dans les différents clusters.

(ref:min) Répartition de la durée moyenne des matchs au sein des clusters

```{r min, fig.cap="(ref:min)", echo = FALSE, eval = TRUE}

df_clean %>% 
  ggplot() + 
  geom_boxplot(mapping = aes(x = as.character(classe_hc), y = min, fill = as.character(classe_hc) )) +
  labs(y = 'Durée moyenne des matchs (minutes)', x = '', fill ='Clusters')

```

La durée moyenne des matchs varie en fonction des clusters. En effet, le cluster 1 a une durée des matchs nettement inférieure à la durée moyenne de 1h45, tandis que les joueurs des clusters 3 et 4 ont joué des matchs avec une durée aux alentours de la durée moyenne. Enfin, les joueurs du cluster 2 ont une tendance à jouer des matchs nettement plus longs que la moyenne. 
Ce phénomène pourrait s'expliquer par le nombre de matchs joués en Grands Chelems par les joueurs des différents clusters.

## Annexe 5 : Corrélation entre le nombre de breaks sauvés et le nombre de breaks affrontés.


(ref:BP) Corrélation entre les balles de break sauvées et subies

```{r BP, fig.cap="(ref:BP)", echo = FALSE, eval = TRUE}

ggplot(data = Base4 ,mapping = aes(x = bpFaced, y = bpSaved)) +
  geom_point() +
  geom_smooth(method="lm") +
  labs(y = 'Points de break sauvés', x = 'Points de break rencontrés')

```

## Annexe 6: ACP pour le cluster 4

(ref:acp) ACP du cluster 4

```{r acp, fig.cap="(ref:acp)", echo = FALSE, eval = TRUE}

acp <- FactoMineR::PCA(Base4,scale.unit = T,graph=FALSE)
fviz_pca(acp)

```
L'ACP permet de confirmer que les deux joueurs cités plus haut ne font pas vraiment partie du bon groupe. En effet, ces derniers peuvent être considerés comme des individus "excentriques". Par ailleurs, la contribution de chacun s'élève à 0.0194 et 0.0549, ceux qui est très faible.
